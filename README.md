# ğŸ“„ Chat com Documentos (RAG)

Um projeto de **Chat com PDFs** usando **RAG (Retrieval-Augmented
Generation)**, construÃ­do com:

-   [Streamlit](https://streamlit.io) â†’ interface web simples e rÃ¡pida\
-   [FAISS](https://github.com/facebookresearch/faiss) â†’ motor de busca
    vetorial\
-   [Sentence-Transformers](https://www.sbert.net) â†’ embeddings
    semÃ¢nticos\
-   [Ollama](https://ollama.ai) â†’ LLM local (ex.: `gemma3:1b`,
    `mistral:7b-instruct`, `llama3.1:8b-instruct`)\
-   [PyPDF](https://pypi.org/project/pypdf/) â†’ extraÃ§Ã£o de texto de PDFs

------------------------------------------------------------------------

## ğŸš€ Funcionalidades

-   Upload de **PDFs** pela interface ou colocar manualmente em
    `./pdfs`\
-   ExtraÃ§Ã£o de texto, divisÃ£o em *chunks* e criaÃ§Ã£o de **Ã­ndice
    vetorial** (FAISS)\
-   Pesquisa semÃ¢ntica nos documentos e **respostas citadas** no chat\
-   IntegraÃ§Ã£o com modelos **Ollama** (funciona 100% local, sem depender
    da cloud)\
-   Controle no sidebar para reconstruir Ã­ndice e escolher o modelo LLM

------------------------------------------------------------------------

## ğŸ“¦ InstalaÃ§Ã£o

### 1. Clonar o repositÃ³rio

``` bash
git clone https://github.com/joaoacabouz/RagPDF.git
cd RagPDF
```

### 2. Criar ambiente virtual

No Windows (PowerShell):

``` powershell
python -3.11 -m venv .venv
.venv\Scripts\activate
```

No Linux/macOS:

``` bash
python3 -m venv .venv
source .venv/bin/activate
```

### 3. Instalar dependÃªncias

``` bash
pip install -r requirements.txt
```

------------------------------------------------------------------------

## âš™ï¸ Uso

### 1. Arrancar o Ollama

Instala o [Ollama](https://ollama.ai/download) e inicia o serviÃ§o:

``` bash
ollama serve
```

Faz *pull* de um modelo (exemplo: Gemma 3 1B):

``` bash
ollama pull gemma3:1b
```

### 2. Executar a aplicaÃ§Ã£o

``` bash
streamlit run app.py
```

### 3. Fluxo na interface

1.  Upload de PDFs pelo sidebar (ou colocar ficheiros em `./pdfs`)\
2.  Clicar em **Build/Rebuild Index** para criar o Ã­ndice FAISS\
3.  Escrever perguntas no chat â†’ respostas aparecem com **citaÃ§Ãµes
    \[1\], \[2\]** que apontam para os PDFs/pÃ¡ginas

------------------------------------------------------------------------

## ğŸ“‚ Estrutura do Projeto

    .
    â”œâ”€â”€ app.py              # CÃ³digo principal Streamlit
    â”œâ”€â”€ requirements.txt    # DependÃªncias
    â”œâ”€â”€ pdfs/               # Colocar aqui os PDFs
    â””â”€â”€ vectorstore/        # Ãndice vetorial gerado automaticamente

------------------------------------------------------------------------

## ğŸ–¼ï¸ Screenshots

### Upload de PDFs

![Upload](docs/screenshots/upload.png)

### Chat com respostas citadas

![Chat](docs/screenshots/chat.png)

------------------------------------------------------------------------

## ğŸ”® Melhorias Futuras

-   Suporte a mais formatos (DOCX, TXT, Markdown)\
-   Modo misto: responder sÃ³ com PDFs ğŸ”’ ou tambÃ©m com conhecimento do
    LLM ğŸŒ\
-   PersistÃªncia do histÃ³rico de chat em ficheiro\
-   Deploy fÃ¡cil em Docker ou Hugging Face Spaces

------------------------------------------------------------------------

## ğŸ“œ LicenÃ§a

Este projeto Ã© apenas para **uso educacional e de portfÃ³lio**.\
Sente-te Ã  vontade para adaptar e melhorar.
